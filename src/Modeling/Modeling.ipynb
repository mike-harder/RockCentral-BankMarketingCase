{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "* Evaluation metric will be accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "import matplotlib.pylab as plt\n",
    "from joblib import dump, load\n",
    "import shap\n",
    "import warnings\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "from os.path import dirname, abspath\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n",
       "0   may         mon       261         1    999         0  nonexistent   \n",
       "1   may         mon       149         1    999         0  nonexistent   \n",
       "2   may         mon       226         1    999         0  nonexistent   \n",
       "3   may         mon       151         1    999         0  nonexistent   \n",
       "4   may         mon       307         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "1           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "2           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "3           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "4           1.1          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dirname(dirname(abspath(\"Modeling.ipynb\")))\n",
    "\n",
    "df = pd.read_csv(d + '/../data/bank-additional/bank-additional-full.csv', sep = \";\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGRESSION_TYPE = \"regression\"\n",
    "CLASSIFICATION_TYPE = \"classification\"\n",
    "\n",
    "PREDICTION_TYPE = CLASSIFICATION_TYPE\n",
    "\n",
    "# this is a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, numeric_features, categorical_features, ordinal_features, ordinal_categories, label, random_state=7, stratify=False):\n",
    "    \"\"\"Helper function to preprocess data. Builds pipeline step for feature scaling, one hot encoding, and split of train/test and validation sets.\n",
    "        ----------\n",
    "        df : pandas dataframe object\n",
    "        numeric_features : list of numerical feature names\n",
    "        categorical_features : list of categorical feature names\n",
    "        numeric_features : list of numerical feature names\n",
    "        ordinal_features : list of ordinal feature names\n",
    "        ordinal_categories : list of ordinal feature categories (list of lists)\n",
    "        label : name of the label column\n",
    "        random_state : int, optional\n",
    "            random seed to use\n",
    "        stratify : boolean, optional\n",
    "            whether to split the data using stratification\n",
    "        Returns\n",
    "        -------\n",
    "        X_cv : X for cross validation \n",
    "        X_validation : X for validation\n",
    "        y_cv : y for cross validation\n",
    "        y_validation : y for validation\n",
    "        preprocessor : pipeline step for preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    # Combine all input features\n",
    "    X = df[numeric_features + categorical_features]\n",
    "\n",
    "    # Encode the output label\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df[label])\n",
    "    \n",
    "    # Create the preprocessing pipelines for both numeric and categorical data\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "            ('ord', OrdinalEncoder(categories = ordinal_categories), ordinal_features)])\n",
    "    \n",
    "    # Create the train/test and validation sets\n",
    "    if stratify:\n",
    "        X_cv, X_validation, y_cv, y_validation = train_test_split(X, y, test_size=0.2, random_state=random_state**1, stratify=y)\n",
    "    else:\n",
    "        X_cv, X_validation, y_cv, y_validation = train_test_split(X, y, test_size=0.2, random_state=random_state**1)\n",
    "\n",
    "    # Return data and pipeline step\n",
    "    return X_cv, X_validation, y_cv, y_validation, preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model(model, param_grid, preprocessor, X_cv, y_cv, n_splits=5, n_repeats=1, random_state=7, preprocess=True, verbose=5):\n",
    "    \"\"\"Helper function to perform repeated k fold cross validation for a model. Uses a grid search to find optimal hyperparameters.\n",
    "        ----------\n",
    "        model : a sklearn model to fit\n",
    "        param_grid : a dictionary of hyperparameter values\n",
    "        preprocessor : pipeline step for preprocessing\n",
    "        X_cv : X for cross validation \n",
    "        y_cv : y for cross validation\n",
    "        n_splits : int, optional\n",
    "            k to use for k fold cross validation\n",
    "        n_repeats : int, optional\n",
    "            number of times to repeat cross validation\n",
    "        random_state : int, optional\n",
    "            k to use for k fold cross validation\n",
    "        preprocess : int, boolean\n",
    "            perform preprocessing steps\n",
    "        verbose : int, optional\n",
    "            amount of printing\n",
    "        Returns\n",
    "        -------\n",
    "        grid : all results from cross validation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all hyperparameters\n",
    "    keys = list(param_grid.keys())\n",
    "    for key in keys:\n",
    "        param_grid['model__' + key] = param_grid.pop(key)\n",
    "    \n",
    "    # Generate pipeline\n",
    "    if preprocess:\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor), ('model', model)])\n",
    "    else:\n",
    "        pipe = Pipeline(steps=[('model', model)])\n",
    "        \n",
    "    # Perform grid search for hyperparameters using repeated k fold cross validation\n",
    "    if PREDICTION_TYPE == CLASSIFICATION_TYPE:\n",
    "        scoring = ['accuracy', 'neg_log_loss']\n",
    "        main_metric = 'accuracy'\n",
    "        refit = 'accuracy'\n",
    "    elif PREDICTION_TYPE == REGRESSION_TYPE:\n",
    "        scoring = 'neg_mean_squared_error'\n",
    "        refit = 'neg_mean_squared_error'\n",
    "    grid = GridSearchCV(pipe, param_grid, cv=RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state**2), n_jobs=-1, return_train_score=True, \n",
    "                                scoring=scoring, refit=refit, verbose=verbose)\n",
    "\n",
    "    # Fit to data\n",
    "    grid.fit(X_cv, y_cv)\n",
    "    \n",
    "    # Return all results of model training\n",
    "    return grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_validation_results(grid, X_validation, y_validation, y_cv):\n",
    "    \"\"\"Helper function to analyze cross validation results and print out metrics.\n",
    "        ----------\n",
    "        grid : all results from cross validation\n",
    "        X_validation : X for validation\n",
    "        y_validation : y for validation\n",
    "        y_cv : y for model training\n",
    "    \"\"\"\n",
    "\n",
    "    # Get index of best result\n",
    "    if PREDICTION_TYPE == CLASSIFICATION_TYPE:\n",
    "        best_param_idx = grid.cv_results_['rank_test_accuracy'].argmin()\n",
    "        # Get metrics\n",
    "        cv_log_loss = -grid.cv_results_['mean_test_neg_log_loss'][best_param_idx]\n",
    "        cv_accuracy = grid.best_score_\n",
    "    elif PREDICTION_TYPE == REGRESSION_TYPE:\n",
    "        best_param_idx = grid.cv_results_['rank_test_score'].argmin()\n",
    "        # Get metrics\n",
    "        cv_MSE = -grid.cv_results_['mean_test_score'][best_param_idx]\n",
    "\n",
    "    # Get best hyperparameter combination\n",
    "    cv_params = grid.best_params_\n",
    "    keys = list(cv_params.keys())\n",
    "    for key in keys:\n",
    "        cv_params[key.split(\"__\")[1]] = cv_params.pop(key)\n",
    "    validation_score = grid.score(X_validation, y_validation)\n",
    "    \n",
    "    # Print out all info\n",
    "    model_name = type(grid.best_estimator_.steps[-1][1]).__name__\n",
    "    if PREDICTION_TYPE == CLASSIFICATION_TYPE:\n",
    "        print(\"{}\\nCross Validation Results:\\n\\tAccuracy: {}\\n\\tLog Loss: {}\\n\\tBest Parameters: {}\\nValidation Accuracy: {}\".format(\n",
    "            model_name, cv_accuracy, cv_log_loss, cv_params, validation_score))\n",
    "    elif PREDICTION_TYPE == REGRESSION_TYPE:\n",
    "        naive_MSE = mean_squared_error(y_validation, [y_cv.mean()]*len(y_validation))\n",
    "        improvement_percentage = (naive_MSE - (-validation_score)) / naive_MSE * 100\n",
    "        print(\"{}\\nCross Validation Results:\\n\\tMSE: {}\\n\\tBest Parameters: {}\\nValidation MSE: {}\\nImprovement: {}%\".format(\n",
    "            model_name, cv_MSE, cv_params, -validation_score, improvement_percentage))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = np.array(classes)\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            if i < 1 :\n",
    "                ax.text(j, i+.2, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "            elif i > 0:\n",
    "                ax.text(j, i-.2, format(cm[i, j], fmt),\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# less important cols from permutation test: day_of_week, housing, age, previous, marital, loan, poutcome\n",
    "\n",
    "numeric_features = ['duration', 'campaign', 'pdays', 'emp.var.rate',\n",
    "                'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "categorical_features = ['job', 'education', 'default', 'contact', 'month']\n",
    "\n",
    "ordinal_features = []\n",
    "\n",
    "ordinal_categories = [[]]\n",
    "\n",
    "label = ['y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_cv, X_validation, y_cv, y_validation, preprocessor =  preprocess_data(df, numeric_features,\n",
    "                                                                        categorical_features, \n",
    "                                                                        ordinal_features,\n",
    "                                                                        ordinal_categories, \n",
    "                                                                        label, stratify = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Accuracy: 0.8873512988589464\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classes, counts = np.unique(y_validation,return_counts=True)\n",
    "print('Naive Accuracy: {}'.format(np.max(counts/len(y_validation))))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Cross Validation Results:\n",
      "\tAccuracy: 0.9100455235204856\n",
      "\tLog Loss: 0.21133493520357072\n",
      "\tBest Parameters: {'C': 1}\n",
      "Validation Accuracy: 0.9124787569798495\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=123)\n",
    "param_grid = {'C': [.01, .05, .1, .5, 1]}\n",
    "grid_LR = cross_validate_model(model, param_grid, preprocessor, X_cv, y_cv, n_splits=3, n_repeats=1, verbose=0)\n",
    "get_cross_validation_results(grid_LR, X_validation, y_validation, y_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEsCAYAAAALni6GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAJqklEQVR4nO3dTY+kVRUA4HOajxFjSExaEmOEuEINMRqasAFmyy/gJ8zvcaGb+iW6cDEMLloa4oKFbIhIDCIdF8SEGRg4LqqRFrqnp98+Xbfq+jxJJdTHW++dTJEz55577s2qCgDosDd6AADMQ1ABoI2gAkAbQQWANoIKAG0EFQDaPDp6AAD0e+TJZ6ruf3rp6+rTj39fVa8uva+gAjChuv9p3Hj2tUtfd/fPv92/yn0FFYApZURuvsIhqADMKCMic+O3FVQAZiVTAaBNc6aSmTcj4m5VHZ73GUEFYEqLayr7mXl06vmqqlYREVV1+6KLBRWAWS3LVI6r6mDpLQUVgBllqKkA0CWHrP6yTQsAbWQqALMy/QVAG82PAPSwTQsAXWzTAkArmQoAPUx/AdBpz/QXAB101APQSkc9ALtMpgIwJYV6ADrpUwGgjUwFgBY5Zut7QQVgVjIVANrIVADoYfUXAJ1kKgC0GLRNi456ANrIVACmpKYCQCc1FQDayFQAaCNTAaBFqqkA0EmmAkCXFFQA6JAxJqhofgSgjUwFYEZ58tgwQQVgSqmmAkAfQQWANoIKAG0EFQB6KNQD0CWvoVCfmTcj4m5VHZ73GUEFYFILg8p+Zh6der6qqlVERFXdvuhiQQVgUguDynFVHSy9p456ANrIVAAmZfUXAD0Grf4y/cXUMvPxb/736dfO+yzMIDMv/bgqmQo772SZ45cRcS8iHo/1v88+j4gbJ+/fP3n9i8ys9Uv5r4h4MiJ+FBEfnVz/yMln/1pVf9/4HwQaXceS4ochqLDzHmaZI/w/ElQA6KOjHoAWKVMBoJHjhAHYaYuCSma+nJn73YMBoM/OLCmuqjtnDP5WRNxaP3n0+fzO9682Mmj2q589PXoIcKa3337ruKp+0PmdO7+k+GQXy1VExN53n6obz77W9dXQ4o+Hvxk9BDjTE4/l+9fyxVZ/AdDC6i8AOgkqALQRVADoo6YCQBeZCgAtuvpOLktHPQBtZCoAkzL9BUAbQQWAPlZ/AdBFpgJAD9u0ANAlI2JATBFUAOa041vfA7BdRmQqmh8BaCNTAZiU6S8AeqRCPQBNMiL29mQqADSRqQDQRk0FgB5qKgB0WXfUy1QAaKGjHoBGOuoB2FqZeTMzX3zQZ2QqAJNaOP21n5lHp56vqmoVEVFVty+6WFABmNHy1V/HVXWw9LaCCsCErP4CoJU+FQDajMhUrP7aYi8890w8//OnRw8DvuWNO6/HJ598MnoYXCDz8o+rkqlssTffeX/0EOBML738yughcJFUUwGgybpQv/n7CioAUxqzTYuaCgBtZCoAkzL9BUAbhXoAejikC4AutmkBoJWgAkAb018AtJGpANBjUKFe8yMAbWQqABPKQdu0CCoAk1KoB6DNnkwFgC4yFQBapEO6AOi0J1MBoItMBYA2aioAtMhY96psmo56ANrIVAAmpVAPQI+0TQsAjRTqAWiRYZsWABrJVABoo6YCQIscdPKjoAIwqRE1Fc2PALSRqQBMasDsl6ACMCuFegBarPtUmr8z85WIuFdVh+d9RlABmNHybVr2M/Po1PNVVa0iIqrq9YsuFlQAJrVw9uu4qg6W3lNQAZiUmgoALa6jpvIwBBWASclUAGgzok9FRz0AbWQqABPKdJ4KAI3sUgxAG4V6ANrIVABokZHbdZ5KZj61yYEA0Ci/Pv3xMo+relCm8mxE/HPJl/7ipz+OP9z59bIRwTX57P6Xo4cAG7VtNZURfTMANBnRiPigoPLexkYBQKuMMZnKgwLZDzc2CgCm8KBM5YmNjQKAdlu1S/HDnPAFwPbaqqACwO5aLxHertVfAOwwmQoAbWzTAkCL9XHCpr8AaLJtzY8A7LAR01+OEwagjUwFYEKZY7a+F1QAJmX1FwBt9KkA0MKSYgBamf4CoEea/gKgUQ44wFdQAZjQuqay+fsKKgCTGhFUdNQD0EamAjAph3QB0EJNBYA+qU8FgEY66gFoYfoLgFYLE5X9zDw69XxVVav19+XNiLhbVYfnXSyoAEwpY29ZR/1xVR2c9UZV3b7oYkEFYEIZjhMGYMfJVABmZJdiADpZUgxAi1E1FUEFYFIyFQDayFQAaJExZnmvoAIwo7T1PQCNBsx+CSoAM1pvKLn5sKKjHoA2MhWASZn+AqCNJcUANEmrvwDooU8FgFYyFQDaKNQD0ENHPQBdRtVUND8C0EZQ2WJvvXkYH/zt/dHDgG95487t+MeHH44eBhfIzEs/rsr01xZ7/oUXRw8BzvTSyzdHD4GHoFAPQBsd9QC0WBfqrf4CoIlMBYAmGSlTAaCLTAWAFmoqAPTJMZmK5kcA2shUACalpgJAG6u/AGiREbEnUwGgi0wFgDZqKgC0kakA0EJNBYBG9v4CoMvyjvr9zDw69XxVVauIiMy8GRF3q+rwvIsFFQBOO66qg7PeqKrbF10sqABMynHCALRYF+rVVABoIlMBoI8lxQB0saQYgDa2aQGgjZoKAH0cJwzALpOpAEwoQ6EegC7L9/66EkEFYFIK9QD02YVMJTOfi4iPqurjb7x+KyJunTz99/73Hnu3YXxE7EfE8ehBwBn8Nvs80/+VO3KeSlW9c87rq4hYXXlE/I/MPDpvG2oYyW9z+6mpANAiQ00FgE4yFc5gSpFt5be55UbUVHTUb7mvzoaGbeO3yVlkKgCTGlGol6lsscx8InPEzwLOd/K7fGT0OLhYLnhclaCypTLzRkT8MiL8z8vWyMzHIuInMWZhEZexJKI0/K2a/tpSVXUvM/9UVV+MHgt8pao+z8y/VNWXo8fCxXai+ZHNEVDYRgLKbsjQ/AhAI82PAPSRqcD1yczHq+qz0eOATVFTgWaZ+UpEfBHr33plZsXX61zeq6oPRo4PZiOoMLWqen30GGAUhXoA2ijUA9BHpgJAh3XhUKEegA6ppgJAIzUVAPrIVADokWoqAPRxSBcAO02mAjChrpMcL0tQAZjVsqiyn5lHp56vqmoV8d+99O5V1eF5FwsqAJNaWKg/rqqDs954mL30BBWASWl+BKCNmgoAPWzTAkAvzY8ANMjQ/AjAjpOpAExKoR6ANgr1ALSxSzEAfWQqAHRRUwGgRWp+BKCTmgoAfWQqAHQZUVPRUQ9AG5kKwKQU6gFokgr1APSwSzEAO0+mAjApNRUA2qipANDDNi0AdMmwoSQAnaz+AmCXyVQAJqVQD0AbhXoA2ijUA9BHpgJAFzUVAFqM2lAyq2rzdwXgWmXm7yJif8Glx1X16uL7CioAdNH8CEAbQQWANoIKAG0EFQDaCCoAtPkPvp4zxOTTN+0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9124787569798495\n",
      "recall 0.4105603448275862\n",
      "precision 0.6864864864864865\n",
      "f1 0.5138233310856373\n",
      "f_1/2: priority on precision 0.6051461245235069\n",
      "f_1.5: priority on recall 0.4685017026106697\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_LR.best_estimator_.predict(X_validation)\n",
    "\n",
    "plot_confusion_matrix(y_validation,y_pred,classes=['no','yes'])\n",
    "plt.show()\n",
    "\n",
    "print('accuracy',accuracy_score(y_validation,y_pred))\n",
    "print('recall',recall_score(y_validation,y_pred))\n",
    "print('precision',precision_score(y_validation,y_pred))\n",
    "print('f1',fbeta_score(y_validation,y_pred,1))\n",
    "print('f_1/2: priority on precision',fbeta_score(y_validation,y_pred,0.5))\n",
    "print('f_1.5: priority on recall',fbeta_score(y_validation,y_pred,1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* KNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "Cross Validation Results:\n",
      "\tAccuracy: 0.9083459787556905\n",
      "\tLog Loss: 0.28106936102706354\n",
      "\tBest Parameters: {'n_neighbors': 25}\n",
      "Validation Accuracy: 0.9129643117261471\n"
     ]
    }
   ],
   "source": [
    "model_kn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': [25, 50, 75]}\n",
    "grid_KNN = cross_validate_model(model_kn, param_grid, preprocessor, X_cv, y_cv, n_splits=3, n_repeats=1, verbose=0)\n",
    "get_cross_validation_results(grid_KNN, X_validation, y_validation, y_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_KNN.best_estimator_.predict(X_validation)\n",
    "\n",
    "plot_confusion_matrix(y_validation,y_pred,classes=['no','yes'])\n",
    "plt.show()\n",
    "\n",
    "print('accuracy',accuracy_score(y_validation,y_pred))\n",
    "print('recall',recall_score(y_validation,y_pred))\n",
    "print('precision',precision_score(y_validation,y_pred))\n",
    "print('f1',fbeta_score(y_validation,y_pred,1))\n",
    "print('f_1/2: priority on precision',fbeta_score(y_validation,y_pred,0.5))\n",
    "print('f_1.5: priority on recall',fbeta_score(y_validation,y_pred,1.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of  27 | elapsed:  3.8min remaining: 47.3min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  27 | elapsed:  4.1min remaining: 17.9min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of  27 | elapsed:  4.1min remaining:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  27 | elapsed:  4.1min remaining:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  14 out of  27 | elapsed:  4.4min remaining:  4.1min\n"
     ]
    }
   ],
   "source": [
    "model_svc = SVC(random_state=123, probability=True)\n",
    "param_grid = {'C': [25, 50, 75], 'gamma': [1e-3, 1e-2, 1e-1]} # try different types of kernels\n",
    "grid_SVC = cross_validate_model(model_svc, param_grid, preprocessor, X_cv, y_cv, n_splits=3, n_repeats=1, verbose=10)\n",
    "get_cross_validation_results(grid_SVC, X_validation, y_validation, y_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_SVC.best_estimator_.predict(X_validation)\n",
    "\n",
    "plot_confusion_matrix(y_validation,y_pred,classes=['no','yes'])\n",
    "plt.show()\n",
    "\n",
    "print('accuracy',accuracy_score(y_validation,y_pred))\n",
    "print('recall',recall_score(y_validation,y_pred))\n",
    "print('precision',precision_score(y_validation,y_pred))\n",
    "print('f1',fbeta_score(y_validation,y_pred,1))\n",
    "print('f_1/2: priority on precision',fbeta_score(y_validation,y_pred,0.5))\n",
    "print('f_1.5: priority on recall',fbeta_score(y_validation,y_pred,1.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = GradientBoostingClassifier(random_state=123)\n",
    "param_grid = {'max_depth': [4, 5, 6], 'n_estimators': [50, 75, 100], 'learning_rate': [.01, .05, .1]}\n",
    "grid_GBC = cross_validate_model(model_xgb, param_grid, preprocessor, X_cv, y_cv, n_splits=3, n_repeats=1, verbose=10)\n",
    "get_cross_validation_results(grid_GBC, X_validation, y_validation, y_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_GBC.best_estimator_.predict(X_validation)\n",
    "\n",
    "plot_confusion_matrix(y_validation,y_pred,classes=['no','yes'])\n",
    "plt.show()\n",
    "\n",
    "print('accuracy',accuracy_score(y_validation,y_pred))\n",
    "print('recall',recall_score(y_validation,y_pred))\n",
    "print('precision',precision_score(y_validation,y_pred))\n",
    "print('f1',fbeta_score(y_validation,y_pred,1))\n",
    "print('f_1/2: priority on precision',fbeta_score(y_validation,y_pred,0.5))\n",
    "print('f_1.5: priority on recall',fbeta_score(y_validation,y_pred,1.5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mlp = MLPClassifier(random_state=123)\n",
    "param_grid = {'hidden_layer_sizes': [(100,), (100,100,), (100,100,100)], 'learning_rate_init': [.01, .001, .0001]}\n",
    "grid_nn = cross_validate_model(model_mlp, param_grid, preprocessor, X_cv, y_cv, n_splits=3, n_repeats=1, verbose=10)\n",
    "get_cross_validation_results(grid_nn, X_validation, y_validation, y_cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_nn.best_estimator_.predict(X_validation)\n",
    "\n",
    "plot_confusion_matrix(y_validation,y_pred,classes=['no','yes'])\n",
    "plt.show()\n",
    "\n",
    "print('accuracy',accuracy_score(y_validation,y_pred))\n",
    "print('recall',recall_score(y_validation,y_pred))\n",
    "print('precision',precision_score(y_validation,y_pred))\n",
    "print('f1',fbeta_score(y_validation,y_pred,1))\n",
    "print('f_1/2: priority on precision',fbeta_score(y_validation,y_pred,0.5))\n",
    "print('f_1.5: priority on recall',fbeta_score(y_validation,y_pred,1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Note: baseline accuracy = 0.887*\n",
    "* XGBoost has marginally outperformed the other models in terms of accuracy, precision, and recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_runs = 10\n",
    "ftr_names = np.array(numeric_features + categorical_features)\n",
    "scores = np.zeros([len(ftr_names),nr_runs])\n",
    "\n",
    "grid = grid_GBC\n",
    "\n",
    "test_score = grid.score(X_validation,y_validation)\n",
    "print('test score = ',test_score)\n",
    "print('test baseline = ',np.sum(y_validation == 0)/len(y_validation))\n",
    "# loop through the features\n",
    "for i in range(len(ftr_names)):\n",
    "    print('shuffling '+str(ftr_names[i]))\n",
    "    acc_scores = []\n",
    "    for j in range(nr_runs):\n",
    "        X_test_shuffled = X_validation.copy()\n",
    "        X_test_shuffled[ftr_names[i]] = np.random.permutation(X_validation[ftr_names[i]].values)\n",
    "        acc_scores.append(grid.score(X_test_shuffled,y_validation))\n",
    "    print('   shuffled test score:',np.around(np.mean(acc_scores),3),'+/-',np.around(np.std(acc_scores),3))\n",
    "    scores[i] = acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indcs = np.argsort(np.mean(scores,axis=1))[::-1]\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.boxplot(scores[sorted_indcs].T,labels=ftr_names[sorted_indcs],vert=False)\n",
    "plt.axvline(test_score,label='test score')\n",
    "plt.title(\"Permutation Importances (test set)\")\n",
    "plt.xlabel('score with perturbed feature')\n",
    "SMALL_SIZE = 0.5\n",
    "plt.rc('font', size=SMALL_SIZE)\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
